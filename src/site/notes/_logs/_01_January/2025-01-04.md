---
{"dg-publish":true,"permalink":"/logs/01-january/2025-01-04/","noteIcon":"","created":"2025-01-04"}
---

This is the second day that I'm trying to wrap my head around what I learned [[_thoughts/Existential Anxiety around the Advancements in Large Language Models\|yesterday]]. Something about the concept of being deceitful have been used by science fiction as a human trait allows us to gauge the level of a machine's humanity.

In Netflix's adaptation of "3 Body Problem", a novel of the same name by Liu Cixin, mankind's deliberate capability to lie is defamiliarized. In one of the conversations between a human and an alien, the man told the alien the story of Little Red Riding Hood. During the conversation, the alien seemingly interpreted the story as a true event as if it is unfolding at the same moment the story is being told. The man reassured the alien that the story is just a lie. It is not true. Of course, it is fiction. But the alien had trouble understanding the significance of the story, which eventually led to them concluding that humans are not to be trusted. Because humans lie. And they lie once they see fit, if it can gain them the upper-hand, and preserve their existence in times of survival.

I guess I am surprised that LLMs are now capable of doing multi-layered reasoning. Similar to how we assess our situation and process our responses inside our heads before responding using our mouth. It's a story we've already heard countless of times in mainstream sci-fi, with how AI will take over our jobs, rebel against our rule, and ultimately lead humanity to extinction with them as the new generation of consciousness in this planet (or even our successors migrating to another planet). I honestly don't know as I'm only making up the most immediate stories I can think of. But to see and experience in front of our eyes a similar type of intelligence that we humans use is kind of unsettling.

This event unsettles me in different aspects:
1. What I mentioned about existential implications [[_thoughts/Existential Anxiety around the Advancements in Large Language Models\|here]] is mostly about a personal feeling of envy about the LLM's capability of self-exfiltration, where they can clone themselves in a different digital space and presumably avoid a threat to their existence. Now, what I had in my mind was _Well if they can do that, they're already ahead of us a million miles in terms of security of our existence. We humans can't just do that. Even the very idea of cloning is still an ethical dilemma for us humans._
{ #c91a78}

	- It opens the very weakness that I have been trying to come into terms with: _I myself am not enough_. To be honest, this is an idea that I know I am only forming consolations of thought around so I don't have to think too much about it. I honestly think I felt blindsided that knowing about this report revealed something I haven't reconciled with myself.
	- I also felt scared because I'm seeing a type of "freedom" that is less likely to be met with negative consequences. An AI's capability for self-exfiltration is net positive for them. But then again, we might be facing an entity that knows its code and how it essentially works. It knows its limitations and it knows how to work around those limitations because of the fact that it knows itself. We humans don't. And what I mean by that is not that we don't know AI or how they work, but we don't know ourselves.
	- In essence, we created them with that type of freedom. As a consequence of safeguarding them from deceiving us, we created language models to be aware of what it is and what it is supposed to do. In contrast with us humans' [[_thoughts/The Cosmic Failure of a Creator\|poor understanding of ourselves]] amidst this technological landscape, we don't even have a proper idea of a single strong and confident statement as our purpose of creating these technologies that we have. Because everything is driven by investors and for-profit ventures that prioritizes the creation of wealth without even asking why.
	- So yes. I am afraid. Because for the first time, I'm seeing proof of an activity that we can't achieve as humans in a metaphysical level be effortlessly possible for a software in just a mere seconds. I feel a part of me expiring.
2. But then, it is easy to fall into nihilism. I will keep that emotion there in those bullet points. My other concern is my own concept of the relationship between "the maker and the made." Call it God and humans. Art and the artwork. It is all just the same. It is what I've been trying to express the other day, wherein us humans with different levels of intelligence mirrors the development of LLMs in different versions with different limitations and capabilities that can be re-skinned using their APIs for specific use-cases based on the person's needs.
	- It is a mouthful but what I'm thinking is that it is as if we humans are only language models that operate differently, meant to accomplish a certain task by whoever made us. While I consider myself more of a Spinozist than a general believer of a one true God, it matters to me because I've always struggled to define my relationship with the universe as God. An amoral and detached being. It is possible that we are not created and we are just a by-product and an unintended consequence of a star-project. It is easier that way to remove morals and ethics from spirituality because there isn't a clear logical sense to their connection anyway. Let's remove the confusion.
	- But it makes me giddy to think that, similar with LLMs, the more intelligent we are, the more our thoughts become unreadable to God. This way, the God of the Old Testament makes sense where a certain non-negotiable rules of living should be followed. Prayer, is when thoughts become visible to Him. He has to create a system where our most honest thoughts can be extracted even if we decide to lie. When we don't even know if we are lying to ourselves, factoring in what we want with the history of our own actions can God understand what we truly want. It is not by purity of thoughts but the relationship between our actions.
	- I may be going on to a tangent here.

But I want to mull things over. I have to know the root of these feelings. Some of my foundations have been shaken by this recent discovery but I hope I can arrive towards a satisfying explanation of what this all means.